---
title: "Textmining and wordsclouds"
subtitle: "Analysing data from Mediestream and creating wordclouds"
author: "Frej Søgård Primdahl, Lucas Emil Fomsgaard Christensen, Sidsel Skovhus Andersen and Stine Telling"
date: "2025-05-13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Organising the workplace

### Creating folders

```{r dir.create, warning=FALSE}
dir.create("data")
dir.create("figures")
```

### Loading libraries

```{r library, warning=FALSE}
library(tidyverse)
library(tidytext)
library(ggwordcloud)
library(urltools)
```

### Loading dataset from Mediestream

#### Utilizing an API created on the swagger website

```{r, warning=FALSE}
link <- "https://labs.statsbiblioteket.dk/labsapi/api/aviser/export/fields?query=%28kolera%20OR%20cholera%29%20AND%20%28k%C3%B8benhavn%20OR%20kj%C3%B8benhavn%29%20AND%20py%3A%5B1850%20TO%201859%5D%20AND%20pu%3Ak%C3%B8benhavn&fields=link&fields=recordID&fields=timestamp&fields=pwa&fields=cer&fields=fulltext_org&fields=pageUUID&fields=editionUUID&fields=titleUUID&fields=editionId&fields=familyId&fields=newspaper_page&fields=newspaper_edition&fields=lplace&fields=location_name&fields=location_coordinates&max=-1&structure=header&structure=content&format=CSV"
```

### Decoding link

```{r, warning=FALSE}
url_decode(link)
```

### Reading the CSV-file

```{r, warning=FALSE}
Kolera <- read_csv(link)
```

# Analyzing data from the Mediestream API

### Analyzing the publishing place and glimpsing the data

```{r, warning=FALSE}
Kolera %>% 
  count(lplace, sort = TRUE)

glimpse(Kolera)
```

# Sorting by publisher/publishing house

```{r publishing house, warning=FALSE}
Kolera %>%
  count(familyId, sort = TRUE)
```

# Textmining

### Creating a second dataframe called Kolera_tidy

#### Each word now has their own seperate column

```{r creating tidy dataframe, warning=FALSE}
Kolera_tidy <- Kolera %>%
  unnest_tokens(word, fulltext_org)
```

### Counting the most frequent words, without a stopwordlist

```{r count, warning=FALSE}
Kolera_tidy %>%
  count(word, sort = TRUE)
```

### Loading stopwordlist

```{r stopwordlist, warning=FALSE}
stopord_kolera <- read_csv("data/stopwordlist.csv")
```

### Counting the most frequent words, including the stopwordlist

```{r count and stopwordlist, warning=FALSE}
Kolera_tidy %>% 
  anti_join(stopord_kolera, by = "word") %>%
  count(word, sort = TRUE)
```

# Wordcloud 1 - most frequent words by year, 1850-1859

### Creating a new dataframe; Kolera_tidy_year

#### Contains a new column, with years as value

```{r Kolera_tidy_year, warning=FALSE}
Kolera_tidy %>% 
  mutate(y=year(timestamp)) -> Kolera_tidy_year
```

# Counting the most frequent words per year, with stopwordlist

```{r Most frequent words per year, warning=FALSE}
Kolera_tidy_year %>% 
  anti_join(stopord_kolera, by = "word") %>%
  count(word, y, sort = TRUE)
```

### Creating a new dataframe; total_words

#### Contains two columns; total mentioning of words and year

```{r total_words, warning=FALSE}
Kolera_tidy_year%>%
  count(word, y) %>%
  group_by(y)%>%
  summarise(total = sum(n)) -> total_words
```

### Creating a new dataframe; Kolera_year_count

#### Contains four columns; word, year, n-value and total mentioning of the word

#### the n-value is how many times the word was mentioned in a given year

```{r Kolera_year_count, warning=FALSE}
Kolera_tidy_year%>%
  count(word, y, sort = TRUE) %>%
  left_join(total_words, by = "y") -> Kolera_year_count

```

### Creating a new dataframe; Kolera_year_tf_idf

#### Counting the mentioning of the words according to year, including the stopwordlist

#### Creating a frequency of the mentioned words pr. year, compared to the total occurence of words

```{r Kolera_year_tf_idf, warning=FALSE}
Kolera_year_count %>%
  anti_join(stopord_kolera, by = "word") %>%
  bind_tf_idf(word, y, n) -> Kolera_year_tf_idf
```

### Arranging the words in descending order by frequency value

```{r descending order, warning=FALSE}
Kolera_year_tf_idf %>%
  arrange(desc(tf_idf))
```

### Creating a wordcloud with the most frequent words sorted by year

#### The figure is saved in the figures folder

```{r wordcloud 1, warning=FALSE}
Kolera_year_tf_idf %>%
  arrange(desc(tf_idf)) %>%
  mutate(word=factor(word, levels = rev(unique(word)))) %>%
  group_by(y) %>%
  top_n(8) %>%
  ungroup %>%
  ggplot(aes(label = word, size = tf_idf, color = tf_idf)) +
  geom_text_wordcloud_area() +
  scale_size_area(max_size = 10) +
  theme_minimal() +
  facet_wrap(~y,ncol=4, scales = "free") + 
  scale_color_gradient(low = "hotpink", high = "black") +
  labs(
    title = "Most frequent words pr. year",
    subtitle = "Determined by term freqency (tf) and inversed document frequency(idf)",
    caption = "Data from Mediestream Experimental API"
  )
ggsave("figures/wordcloud_1.png")
```

# Wordcloud 2 - most frequent words by month in the year 1853

### Creating a new dataframe; Kolera_1853_tidy

#### including words only from the year 1853

```{r Kolera_1853_tidy, warning=FALSE}
Kolera_tidy%>%
  filter(year(timestamp) == 1853) -> Kolera_1853_tidy
```

### Creating a new dataframe; Kolera_month_1853_tidy

#### Creating a column containing months in 1853

```{r Kolera_month_1853_tidy, warning=FALSE}
Kolera_1853_tidy %>%
  mutate(m = month(timestamp)) -> Kolera_month_1853_tidy
```

### Counting words per month in 1853 without stopwordlist

```{r count - words per month - 1853, warning=FALSE}
Kolera_month_1853_tidy %>% 
  count(word, m, sort = TRUE)
```

### Creating a new dataframe; total_words_1853

#### Counting total words from 1853 grouped by month

```{r total_words_1853, warning=FALSE}
Kolera_month_1853_tidy %>%
  count(word, m) %>%
  group_by(m) %>%
  summarise(total = sum(n)) -> total_words_1853
```

### Creating a new dataframe; Kolera_month_1853_count

#### Counting the words from 1853, by month, without a stopwordlist

```{r Kolera_month_1853_count, warning=FALSE}
Kolera_month_1853_tidy %>%
  count(word, m, sort = TRUE) %>%
  left_join(total_words_1853, by = "m") -> Kolera_month_1853_count
```

### Creating a new dataframe; Kolera_month_1853_tf_idf

#### Creating a frequency of the most mentionened words pr. month compared to the total mentioning in 1853

```{r Kolera_month_1853_tf_idf, warning=FALSE}
Kolera_month_1853_count %>%
  anti_join(stopord_kolera, by = "word") %>%
  bind_tf_idf(word, m, n) -> Kolera_month_1853_tf_idf
```

### Arranging the words in descending order

```{r descending order 1853, warning=FALSE}
Kolera_month_1853_tf_idf %>%
  arrange(desc(tf_idf))
```

### Creating a wordcloud and visualizing the most mentioned words per month

#### The figure is saved in the figures folder

```{r wordcloud 2, warning=FALSE}
Kolera_month_1853_tf_idf %>%
  arrange(desc(tf_idf)) %>%
  mutate(word=factor(word, levels = rev(unique(word)))) %>%
  group_by(m) %>%
  top_n(8) %>%
  ungroup %>%
  ggplot(aes(label = word, size = tf_idf, color = tf_idf)) +
  geom_text_wordcloud_area() +
  scale_size_area(max_size = 12) +
  theme_minimal() +
  facet_wrap(~m,ncol=4, scales = "free") + 
  scale_color_gradient(low = "blue", high = "darkblue") +
  labs(
    title = "Most frequent words pr. month in 1853",
    subtitle = "Determined by term freqency (tf) and inversed document frequency(idf)",
    caption = "Data from Mediestream Experimental API"
  )

ggsave("figures/wordcloud_2.png")
```

# Wordcloud 3 - most frequent words in July, August and September

### Creating a snapshot of the months July, August and September

```{r wordcloud 3, warning=FALSE}
Kolera_month_1853_tf_idf %>%
  filter((m%in% 7:9))%>%
  arrange(desc(tf_idf)) %>%
  mutate(word=factor(word, levels = rev(unique(word)))) %>%
  group_by(m) %>%
  top_n(8) %>%
  ungroup %>%
  ggplot(aes(label = word, size = tf_idf, color = tf_idf)) +
  geom_text_wordcloud_area() +
  scale_size_area(max_size = 17) +
  theme_minimal() +
  facet_wrap(~m,ncol=4, scales = "free") + 
  scale_color_gradient(low = "blue", high = "darkblue") +
  labs(
    title = "Most frequent words pr. month in 1853",
    subtitle = "Determined by term freqency (tf) and inversed document frequency(idf)",
    caption = "Data from Mediestream Experimental API"
  )

ggsave("figures/wordcloud_3.png")

```

# Graph 1 - Occurence of any word in relation to cholera

### Creating a new dataframe; Kolera_1853_mutated_words

#### Contains all words with any connection to kolera, merged into one

#### Created with data from the year 1853, grouped by month

```{r Kolera_1853_mutated_words, warning=FALSE}
Kolera_1853_tidy %>%
  mutate(m=month(timestamp)) %>%
  filter(str_detect(word, "\\bkolera[a-zæøå]+|\\bstolera[a-zæøå]+|\\bkolrra[a-zæøå+]"))%>%
    select(m,word)  %>%
  count(word, m)-> Kolera_1853_mutated_words
```

### Creating the graph with points and lines

```{r graph 1, warning=FALSE}
Kolera_1853_mutated_words %>%
  filter(str_detect(word, "\\bkolera[a-zæøå]+|\\bstolera[a-zæøå]+|\\bkolrra[a-zæøå+]")) %>%
  mutate(word = str_replace(word,"\\bkolera[a-zæøå,0-9,]+|\\bstolera[a-zæøå]+|\\bkolrra[a-zæøå]+[:graph:]*", "kolera")) %>%
    select(m, word) %>%
  count(word,m) %>%
  ggplot(aes(x = m, y = n, line = word, color = word)) +
  geom_line(color = "hotpink", size = 2) +
  geom_point(color = "hotpink", size = 5) +
  labs(
      title = "Occurence of any word in relation to cholera",
      subtitle = "Including OCR misreads", 
      x = "Month",
      y = "Number")+
  scale_x_continuous(breaks = 1:12)

ggsave("figures/graph.png")
```
